<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mood Detector & Music Player ðŸŽµ</title>
    <script defer src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
    <style>
        body {
            font-family: Arial, sans-serif;
            text-align: center;
            background-color: #f4f4f4;
            padding: 20px;
        }
        video {
            width: 100%;
            max-width: 500px;
            border-radius: 10px;
            border: 2px solid #333;
        }
        #mood {
            font-size: 40px;
            margin-top: 10px;
        }
        #music {
            margin-top: 20px;
            font-size: 20px;
            font-weight: bold;
        }
    </style>
</head>
<body>
    <h1>ðŸŽµ Mood-Based Music Player</h1>
    <video id="video" autoplay playsinline></video>
    <p id="mood">Detecting mood... ðŸ¤”</p>
    <p id="music">Music: ðŸŽµ None</p>
    <audio id="audioPlayer" controls>
        <source id="audioSource" src="" type="audio/mp3">
        Your browser does not support the audio element.
    </audio>

    <script>
        const video = document.getElementById("video");
        const moodText = document.getElementById("mood");
        const musicText = document.getElementById("music");
        const audioPlayer = document.getElementById("audioPlayer");
        const audioSource = document.getElementById("audioSource");

        const moodEmojis = {
            happy: "ðŸ˜ƒ Happy",
            sad: "ðŸ˜¢ Sad",
            angry: "ðŸ˜¡ Angry",
            surprised: "ðŸ˜² Surprised",
            neutral: "ðŸ˜ Neutral",
            fearful: "ðŸ˜¨ Fearful",
            disgusted: "ðŸ¤¢ Disgusted"
        };

        const moodMusic = {
            happy: "https://www.bensound.com/bensound-music/bensound-ukulele.mp3",
            sad: "https://www.bensound.com/bensound-music/bensound-slowmotion.mp3",
            angry: "https://www.bensound.com/bensound-music/bensound-actionable.mp3",
            surprised: "https://www.bensound.com/bensound-music/bensound-epic.mp3",
            neutral: "https://www.bensound.com/bensound-music/bensound-buddy.mp3",
            fearful: "https://www.bensound.com/bensound-music/bensound-creepy.mp3",
            disgusted: "https://www.bensound.com/bensound-music/bensound-deep.mp3"
        };

        async function startCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video.srcObject = stream;
            } catch (error) {
                console.error("Error accessing webcam:", error);
                moodText.textContent = "Webcam access denied ðŸš«";
            }
        }

        async function loadModels() {
            console.log("Loading face detection models...");
            await faceapi.nets.tinyFaceDetector.loadFromUri("https://cdn.jsdelivr.net/npm/face-api.js/weights/");
            await faceapi.nets.faceExpressionNet.loadFromUri("https://cdn.jsdelivr.net/npm/face-api.js/weights/");
            console.log("Models loaded successfully.");
        }

        async function detectMood() {
            if (!video || video.videoWidth === 0) return; // Prevent errors if camera is not ready

            const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions()).withFaceExpressions();

            if (detections.length > 0) {
                const expressions = detections[0].expressions;
                const maxExpression = Object.keys(expressions).reduce((a, b) => expressions[a] > expressions[b] ? a : b);
                
                moodText.textContent = moodEmojis[maxExpression] || "ðŸ¤” Detecting...";
                
                if (moodMusic[maxExpression]) {
                    audioSource.src = moodMusic[maxExpression];
                    audioPlayer.load();
                    audioPlayer.play();
                    musicText.textContent = `ðŸŽµ Now Playing: ${moodEmojis[maxExpression]}`;
                }
            } else {
                moodText.textContent = "No face detected ðŸ‘€";
                musicText.textContent = "Music: ðŸŽµ None";
                audioPlayer.pause();
            }
        }

        async function startDetection() {
            console.log("Starting mood detection...");
            await loadModels();
            console.log("Mood detection started.");
            setInterval(detectMood, 2000); // Detect mood every 2 seconds
        }

        startCamera();
        video.addEventListener("playing", startDetection);
    </script>
</body>
</html>
